{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNO2nU8Zde9vb//inwfUBcX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["http://nlp.seas.harvard.edu/annotated-transformer/"],"metadata":{"id":"gAt87I3PemjE"}},{"cell_type":"markdown","source":["Table of Contents\n","\n","1. Prelims\n","2. Backgrounmd\n","3. Part 1 : Model Architecture\n","  \n","  - Encoder and Decoder Stacks\n","  - Position-wise FFN\n","  - Embeddings and Softmax\n","  - PE\n","  - Full Model\n","\n","4. Part 2 : Model Training\n","  \n","  - Batches and Masking\n","  - Training Loop\n","  - Hardware and Schedule\n","  - Optimizer\n","  - Regularization"],"metadata":{"id":"xgbaHqy5ezRG"}},{"cell_type":"markdown","source":["#1. Prelims"],"metadata":{"id":"lQoedW63fMKD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5P8gSHZzqbuZ"},"outputs":[],"source":["!pip install -r requirements.txt"]},{"cell_type":"code","source":["!pip install -q torchdata == 0.3.0 torchtext == 0.12 spacy == 3.2 altair GPUtil\n","!python -m spacy download de_core_news_sm\n","!python -m spacy download en_core_web_sm"],"metadata":{"id":"Lu2tCRD8fQkq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","from os.path import exists\n","import torch\n","import torch.nn as nn\n","from torch.nn.functional import log_softmax, pad\n","\n","import math\n","import copy\n","import time\n","\n","from torch.optim.lr_scheduler import LambdaLR\n","\n","import pandas as pd\n","import altair as alt\n","\n","from torchtext.data.functional import to_map_style_dataset\n","from torchtext.vocab import build_vocab_from_iterator\n","\n","import torchtext.datasets import datasets\n","from torch.utils.data import DataLoader\n","\n","import spacy\n","import GPUtil\n","import warnings\n","\n","from torch.utils.data.distributed import DistributedSampler\n","\n","import torch.distributed as dist\n","import torch.multiprocessing as mp\n","from torch.nn.parallel import DistributedDataPalallel as DDP\n","\n","warnings.filterwarnings('ignore')\n","run_examples = True"],"metadata":{"id":"S9VNPglmfc3q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# some convenience helper functions used throughout the notebook\n","\n","def is_interactive_notebook() :\n","  return __name__ == '__main__'\n","\n","def show_examples(fn, args=[]) :\n","  if __name__ == '__main__' and run_examples :\n","    return fn(*args)\n","\n","def execute_examples(fn, args=[]) :\n","  if __name__ == '__main__' and run_examples :\n","    return fn(*args)\n","\n","class DummyOptimizer(torch.optim.Optimizer) :\n","  def __init__(self) :\n","    self.param_groups = [{'lr' : 0}]\n","    None\n","  \n","  def step(self) :\n","    None\n","  \n","  def zero_grad(self, set_to_none=False) :\n","    None\n","  \n","\n","Class DummyScheduler :\n","def step(self) :\n","  None"],"metadata":{"id":"jcW9tY8_gOLR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2. Model Architecture"],"metadata":{"id":"ODTliojriEkD"}},{"cell_type":"code","source":["class EncoderDecoder(nn.Module) :\n","  '''\n","  A standard Encoder-Decoder architecture.\n","  '''\n","\n","  def __init__(self, encoder, decoder, src_embed, tgt_embed, generator) :\n","    super(EncoderDecoder, self).__init__()\n","    self.encoder = encoder\n","    self.decoder = decoder\n","    self.src_embed = src_embed\n","    self.tgt_embed = tgt_embed\n","    self.generator = generator\n","\n","  \n","  def forward(self, src, tgt, src_mask, tgt_mask) :\n","    'take in and process maksed src and tgt sequence'\n","    return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)\n"," \n","  def encode(self, src, src_mask) :\n","    return self.encoder(self.src_embed(src), src_mask)\n","\n","  def encoder(self, memory, src_mask, tgt, tgt_mask) :\n","    return self.decoder(self.tgt_embed(tgt), memory, tgt_mask, src_mask)\n","\n","class generator(nn.Module) :\n","  'Define standard linear + softmax'\n","\n","  def __init__(self, d_model, vocab) :\n","    super(generator,self).__init__() \n","    self.proj = nn.Linear(d_model, vocab)\n","\n","  def forward(self,x) :\n","    return log_softmax(self.proj(x), dim=-1)"],"metadata":{"id":"ghAqDQCmiGRq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Encoder and Decoder Stacks"],"metadata":{"id":"t2VqgS_Ajmv8"}},{"cell_type":"markdown","source":["### Encoder\n","\n","the encoder is composed of a stack N=6 of identical layers"],"metadata":{"id":"6PzDJOkkjoq-"}},{"cell_type":"code","source":["# N = 6\n","class clones(nn.Module) :\n","  return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n"],"metadata":{"id":"xrZ22ZRYi2W2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Encoder(nn.Module) :\n","  'Core encoder is a stack of N layers'\n","\n","  def __init__(self, layer, N) :\n","    super(Encoder,self).__init__()\n","    self.layers = clones(layer,N)\n","    self.norm = LayerNorm(layer.size)\n","\n","  def forward(self, x, mask) :\n","    for layer in self.layers :\n","      x = layer(x,mask)\n","    return self.norm(x)"],"metadata":{"id":"uKUllXRMj3vb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["residual connection around each of the two sublayers, followed by layer norm"],"metadata":{"id":"5PkblSqxkQI2"}},{"cell_type":"code","source":["class LayerNorm(nn.Module) :\n","  def __init__(self,features,eps=1e-6) :\n","    super(LayerNorm,self).__init__()\n","    self.a_2 = nn.Parameter(torch.ones(features))\n","    self.b_2 = nn.Parameter(torch.zeros(featrues))\n","    self.eps = eps\n","\n","  def forward(self,x) :\n","    mean = x.mean(-1, keepdim=True)\n","    std = x.std(-1, keepdim=True)\n","    return self.a_2 * (x-mean) / (std_sels.eps) _ self.b_2"],"metadata":{"id":"5dpVGmpPkPey"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["To faciliate these residual connections, all sub-layers in the model, as well as the embedding layers, produce outputs of d_model == 512"],"metadata":{"id":"T0rhQ1WykySE"}},{"cell_type":"code","source":["class SublayerConnection(nn.Module) :\n","\n","  def __init__(self, size, dropout) :\n","    super(SublayerConnection,self).__init__()\n","    self.norm = LayerNorm(size)\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self,x,sublayer) :\n","    return x+ self.dropout(sublayer =(self.norm(x)))\n","\n","  "],"metadata":{"id":"ftMVDuyLk6UY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Each layer has 2 sublayer. 1st is multi headed, 2nd is position wised fully connected FFN"],"metadata":{"id":"Fc1XTznllOWe"}},{"cell_type":"code","source":["class EncoderLayer(nn.Module) :\n","\n","  def __init__(self, size, self_attn, ff, dropout) :\n","    super(EncoderLayer,self).__init__()\n","\n","    self.self_attn = self_attn\n","    self.ff = ff\n","    self.sublayer = clones(SublayerConnection(size, dropout), 2)\n","    self.size = size\n","\n","  def forward(self,x,mask) :\n","    x = self.sublayer[0](x, lambda x : self.self_attn(x,x,x,mask))\n","    return self.sublayer[1](x, self.ff)"],"metadata":{"id":"bTwdh9h4lWDz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Decoder\n","\n","The decoder is also composed of a stack of N=6 identical layer"],"metadata":{"id":"EkPBct5flyV0"}},{"cell_type":"code","source":["class Decoder(nn.Module) :\n","\n","  def __init__(self, layer, N) :\n","    super(Decoder,self).__init__()\n","    self.layers = clones(layer,N)\n","    self.norm  = LayerNorm(layer.size)\n","\n","  def forward(self,x,src_mask, memory, tgt_mask): \n","    for layer in self.layers :\n","      x = layer(x, memory, src_mask, tgt_mask)\n","    \n","    return self.norm(x)"],"metadata":{"id":"5kmJk9sklvi9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DecoderLayer(nn.Module) :\n","\n","  def __init__(self, size, self_attn, src_attn, ff, dropout) :\n","    super(DecoderLayer,self).__init__()\n","\n","    self.size = size\n","    self.self_attn = self_attn\n","    self.src_attn = src_attn\n","    self.ff = ff\n","    self.sublayer = clones(SublayerConnection(size,dropout),3)\n","\n","  def forward(self,x,memory,src_mask,tgt_mask) :\n","    m = memory\n","    x = self.sublayer[0](x, lambda x : self.self_attn(x,x,x,tgt_mask))\n","    x = self.sublayer[1](x, lambda x : self.src_attn(x,m,m,src_mask))\n","\n","    return self.sublayer[2](x, self.ff)"],"metadata":{"id":"4lcEnqMcmO9C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Make Masking to prevent positions from attending to subsequent positions."],"metadata":{"id":"Tp473Fsenw7I"}},{"cell_type":"code","source":["def subsequent_mask(size) :\n","  'Mask out subsequent positions'\n","  attn_shape = (1,size,size)\n","  subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(torch.unit8)\n","\n","  return subsequent_mask == 0"],"metadata":{"id":"JH_6o1bAnhU0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Attnetion\n","\n","An attention function can be described as mapping a query and a set of key-value paris to an output, where the query,key,values, and output are all vectors.\n","\n","The output is computed as a weighted sum of the values.\n","\n","We call our particular attention 'Scaled dot product attention'.\n","\n","Attention(Q,K,V) = Softmax(QK^T / sqrt(d_k)V\n"],"metadata":{"id":"N88jWY0kmkJ3"}},{"cell_type":"code","source":["def attention(query, key, value, mask=None, Dropout=None) :\n","\n","  d_k = query.size(-1)\n","  softmax_scores = torch.matmul(query, key.transpose(-2,-1)) / sqrt(d_k)\n","\n","  if mask is not None :\n","  softmax_scores = softmax_scores.masked_fill(mask == 0, -1e9)\n","\n","  p_attn = softmax_scores.softmax(dim=-1)\n","\n","  if dropout is not None :\n","    p_attn = dropout(p_attn)\n","  \n","  return torch.matmul(p_attn, value), p_attn"],"metadata":{"id":"aYUDeUJHoW-q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Multihead\n","\n","Multihead(Q,K,V) = Concat(head1,,,,,head_h)Wo\n","\n","where head_i = Attention(QW_I^Q, KW_I^K, VW_I^V)\n","\n"],"metadata":{"id":"7AKfL18go_FG"}},{"cell_type":"code","source":["class MultiHeadedAttention(nn.Module) :\n","\n","  def __init__(self, h, d_model, dropout=0.1) :\n","    super(MultiHeadedAttention,self).__init__()\n","    assert d_model %h == 0\n","\n","    self.d_k = d_model / h\n","    self.h = h\n","    self.linears = clones(nn.Linear(d_model, d_model), 4)\n","    self.attn = None\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self,query,key,value, maks=None) :\n","    if mask is not None :\n","      mask = mask.unsqueeze(1)\n","    \n","    nbatches = query.size(0)\n","\n","    query,key,value = [\n","        lin.(x).view(nbatches, -1, self.h, self.d_k).transpose(1,2)\n","    ]\n","\n","    x, self.attn = attention(\n","        query, key, value, mask=mask, dropout=self.dropout\n","      \n","    )\n","\n","    x = (\n","        x.transpose(1,2)\n","        .contiguous()\n","        .view(nbatches, -1, self.h * self.d_k)\n","    )\n","\n","    del query\n","    del key\n","    del value\n","\n","    return self.linears[-1](x)"],"metadata":{"id":"G1QHJqiEpQx-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Applications of Attnetion in Model\n","\n","1. Encoder-Decoder attention\n","\n","2. Self-attention layers in Encoder\n","\n","3. self attention layers in Decoder with masking"],"metadata":{"id":"w2glxtK7qWHO"}},{"cell_type":"markdown","source":["## Position-wised FFN"],"metadata":{"id":"80BLHh5Pqj4e"}},{"cell_type":"code","source":["class PositionWiseFF(nn.Module) :\n","\n","  def __init__(self, d_model, d_ff, dropout=0.1) :\n","    super(PositionWiseFF,self).__init__()\n","\n","    self.w_1 = nn.Linear(d_model, d_ff)\n","    self.w_2 = nn.Linear(d_ff, d_model)\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self,x) :\n","    return self.w_2(self.dropout(self.w_1(x).relu()))"],"metadata":{"id":"670V3cyCqSuf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Embedding and Softmax"],"metadata":{"id":"-FWE8bnCvfVi"}},{"cell_type":"code","source":["class Embedding(nn.Module) :\n","  def __init__(self, d_model, vocab) :\n","    super(Embedding,self).__init__()\n","\n","    self.lut = nn.Embedding(vocab, d_model)\n","    self.d_model = d_model\n","\n","  def forward(self,x) :\n","    return self.lut(x) * sqrt(self.d_model)"],"metadata":{"id":"H3pSPapmvhu_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Position Encoding\n","\n","PE(pos,2i) = sin(pos/ 10000^2i/d_model)\n","\n","PE(pos,2i+1) = cos(pos/ 10000^2i/d_model)\n","\n"],"metadata":{"id":"ri-OARvMvuXF"}},{"cell_type":"code","source":["class PE(nn.Module) :\n","\n","  def __init__(self, d_model, dropout, max_len = 5000) :\n","\n","    super(PE,self).__init__()\n","\n","    self.dropout = nn.Dropout(dropout)\n","\n","    pe = torch.zeros(max_len, d_model)\n","\n","    position = torch.arange(0, max_len).unsqueeze(1)\n","\n","    div_tern = torch.exp(\n","        torch.arange(0, d_model,2) * -(math.log(10000) / d_model)\n","    )\n","\n","    pe[:,0::2] = torch.sin(position * div_term)\n","    pe[:,1::2] = torch.cos(position * div_term)\n","\n","    pe = pe.unsqueeze(0)\n","    self.register_buffer('pe',pe)\n","\n","  def forward(self, x) :\n","    x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n","\n","    return self.dropout(x)"],"metadata":{"id":"BwHjO3gevvmv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Full Model"],"metadata":{"id":"ce0ag5hWxQ8Q"}},{"cell_type":"code","source":["def make_model(src_vocab, tgt_vocab, N=6, d_model = 512, d_ff= 2048, h=8, dropout=0.1) :\n","\n","  c = copy.deepcopy()\n","  attn = MultiHeadedAttention(h, d_model)\n","  ff = PositionwiseFF(d_model, d_ff, dropout)\n","  position = PE(d_model, dropout)\n","\n","  model = EncoderDecoder(\n","      Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n","      Decoder(DecoderLayer(d_model, c(attn), c(attn), dropout),N),\n","      nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n","      nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n","      Generator(d_model, tgt_vocab)\n","  )\n","\n","  # This was importrant from their code.\n","  # Initialize parameters with Glorot/ fan_avg\n","\n","  for p in model.Parameters() :\n","    if p.dim() >1 :\n","      nn.init.xavier_uniform(p)\n","  \n","  return model"],"metadata":{"id":"TL8XD0DjwovU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Batches and Masking"],"metadata":{"id":"J_3fpzHXyMJ_"}},{"cell_type":"code","source":["class batch :\n","  'Object for holding a batch of data with mask during training'\n","\n","  def __init__(self, src, tgt=None, pad=2) :\n","    self.src = src\n","    self.src_mask = (src != pad).unsqueeze(-2)\n","\n","    if tgt is not None :\n","      self.tgt = tgt[:,:-1]\n","      self.tgt_y = tgt[:,1:]\n","      self.tgt_mask = self.make_std_mask(self.tgt, pad)\n","      self.ntokens = (self.tgt_y != pad).data.sum()\n","\n","    \n","  @staticmethod\n","  def make_std_mask(tgt,pad) :\n","    tgt_mask = (tgt!=pad).unsqueeze(2)\n","    tgt_mask = tgt_mask & subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data)\n","\n","    return tgt_mask"],"metadata":{"id":"AEFlpeMS8hhh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training Loop"],"metadata":{"id":"cxTTMrcHyOHz"}},{"cell_type":"code","source":["class TrainState : \n","  step : int =0\n","  accum_step : int = 0\n","  samples : int = 0\n","  tokens : int = 0\n"],"metadata":{"id":"0JGSt3Lo9m0g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def run_epoch(\n","    data_iter,\n","    model,\n","    loss_compute,\n","    optimizer,\n","    scheduler,\n","    mode='train',\n","    accum_iter =1,\n","    train_state = TrainState()\n",") :\n","  for i, batch in enumerate(data_iter) :\n","    out = model.forward(batch.src, batch.tgt, batch.src_mask, batch.tgt_mask)\n","    loss, loss_node = loss_compute(out, batch.tgt_y, batch.ntokens)\n","\n","    if mode == 'train' or mode == 'train+log' :\n","      loss_node.backward()\n","      train_state.step +=1\n","      train_state.samples += batch.src.shape[0]\n","      train_state.tokens += batch.ntokens\n","\n","      if i % accum_iter == 0 :\n","        optimizer.step()\n","        optimizer.zero_grad(set_to_none=True)\n","        n_accum+=1\n","        train_state.accum_step +=1 \n","    \n","    scheduler.step()\n","\n","  total_loss += loss\n","  total_tokens += batch.ntokens\n","  tokens += batch.ntokens\n","\n","  if i % 40 ==1 and (mode == 'train' or mode == 'train+log') :\n","    lr = optimizer.param_groups[0]['lr']\n","    elapsed = time.time() - start\n","\n","    start = time.time()\n","    ntokens = 0\n","  del loss\n","  del loss_node\n","\n","return total_loss / total_tokens, train_state\n","\n"],"metadata":{"id":"w2woUP6y9sBT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Optimizer"],"metadata":{"id":"43FeCdOKyQYN"}},{"cell_type":"code","source":["def rate(step,model_size, factor, warmup) :\n","  if step == 0 :\n","    step = 1\n","  return factor * (\n","      model_size ** (-0.5)* min(step ** (-0.5), step* warmup**(-1.5))\n","  )"],"metadata":{"id":"ta5E81fy-yPH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Regularization"],"metadata":{"id":"j5GYyTpnyRzq"}},{"cell_type":"code","source":["class LabelSmoothing(nn.Module) :\n","\n","  def __init__(self, size, padding_idx, smoothing = 0.0) :\n","    super(LabelSmoothing,self).__init__()\n","    self.criterion = nn.KLDivLoss(reduction='sum')\n","    self.padding_idx = padding_idx\n","    self.confidence = 1.0 - smoothing\n","    self.smoothing = smoothing\n","    self.size = size\n","    self.true_dist = None\n","\n","  def forward(self, x, target) :\n","    assert x.size(1) == self.size\n","\n","    true_dist = x.data.clone()\n","    true.dist.fill_(self.smoothing / (self.size -2))\n","    true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n","    true_dist[:, self.padding_idx] = 0\n","    mask = torch.nonzero(target.data == self.padding_idx)\n","\n","    if mask.dim() > 0 :\n","      true_dist.index_fill(0, mask.squeeze(),0.0)\n","    \n","    self.true_dist = true_dist\n","    return self.criterion(x, true_dist.clone().detach())"],"metadata":{"id":"gM2Q3bHl_A3P"},"execution_count":null,"outputs":[]}]}