{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP9EOvswu6p/9rCaVpBaXbX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ozXc92HHokSh"},"outputs":[],"source":["# pip install -r requirements.txt"]},{"cell_type":"code","source":["# !pip install -q torchdata=0.3.0 torchtext==0.12\n","# !pip install spacy==3.0, altair GPUtil\n","# !python -m spacy download de_core_news_sm\n","# !python -m spacy download en_core_web_sm"],"metadata":{"id":"zC_a_pWZo0Ri"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","from os.path import exists\n","import torch\n","import torch.nn as nn\n","from torch.nn.functional import log_softmax, pad\n","import math\n","import copy\n","from torch.optim.lr_scheduler import LambdaLR\n","\n","import pandas as pd\n","import altair as alt\n","\n","from torchtext.data.functional import to_map_style_dataset\n","from torch.utils.data import DataLoader\n","from torchtext.vocab import build_vocab_from_iterator\n","\n","import torchtext.datasets as datasets\n","\n","import spacy\n","import GPUtil\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from torch.utils.data.distributed import DistributedSampler\n","import torch.distributed as dist\n","import torch.multiprocessing as mp\n","from torch.nn.parallel import DistributedDataParallel as DDP\n","\n","run_exaples_True"],"metadata":{"id":"XWpO4CcXpB0g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def is_interactive notebook() :\n","  return __name__ == '__main__'\n","\n","def show_example(fn, args=[]) :\n","  if __name__ == '__main__' & run_examples :\n","    return fn(*args)\n","  \n","def execute_example(fn, args=[] ) :\n","  if __name__ == '__main__' & run_examples :\n","    return fn(*args))\n","\n","  \n","class DummyOptimizer(torch.optim.Optimizer) :\n","  def __init__(self) :\n","    self.param_groups = [{'lr' : 0}]\n","    None\n","  \n","  def step(self) :\n","    None\n","  \n","  def zero_grad(self, set_to_none = False) :\n","    None\n","  \n","\n","Class DummyScheduler :\n","def step(self) :\n","  None\n","  "],"metadata":{"id":"0anPQyDSpsCT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Model Architecture"],"metadata":{"id":"s7NvbzT6qXex"}},{"cell_type":"code","source":["class EncoderDecoder(nn.Module) :\n","\n","  def __init__(self, encoder, decoder, src_embed, tgt_embed, generator) :\n","    super(EncoderDecoder,self).__init__()\n","\n","    self.encoder = encoder\n","    self.decoder = decoder\n","    self. src_embed = src_embed\n","    self.tgt_embed = tgt_embed\n","    self.generator = generator\n","\n","  def forward(self, src, tgt, src_mask, tgt_mask) :\n","    return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)\n","  \n","  def encode(self, src, src_mask) :\n","    reutrn self.encoder(self.src_embed(src), src_mask)\n","  \n","  def decode(self, memory, src_mask, tgt, tgt_mask) :\n","    return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)"],"metadata":{"id":"ww8U4yh6qaIQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Generator(nn.Module) :\n","  def __init__(self, d_model, vocab) :\n","    super(Generator,self).__init__()\n","\n","    self.prob = nn.Linear(d_model, vocab)\n","\n","  def forward(self, x) :\n","    return log_softmax(self.prob(x), dim=-1)\n","\n","    "],"metadata":{"id":"Zb0zqxq_rGtt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Encoder and Decoder Stacks"],"metadata":{"id":"_uafbD6mrZn0"}},{"cell_type":"markdown","source":["Encoder \n","\n","The encoder is composed of a stack of N=6 identical layers"],"metadata":{"id":"5ZdDXqhDrdBm"}},{"cell_type":"code","source":["def clones(module, N) :\n","  return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"],"metadata":{"id":"ULiv1KhErblZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Encoder(nn.Module) :\n","  def __init__(self, layer, N) :\n","    super(Encoder,self).__init__()\n","    self.layers =clones(layer, N)\n","    self.norm = LayerNorm(layer.size)\n","\n","  def forward(self, x, mask) :\n","    for layer in self.layers :\n","      x = layer(x, mask)\n","  \n","    return self.norm(x)"],"metadata":{"id":"WYY-56aLqSfK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class LayerNorm(nn.Module) :\n","\n","  def __init__(self, features, eps=1e-6) :\n","    super(LayerNorm,self).__init__() \n","    self.a_2 = nn.Parameter(torch.ones(features))\n","    self.b_2 = nn.Parameter(torch.zeros(feature))\n","    self.eps = eps\n","\n","  def forward(self, x) :\n","    mean = x.mean(-1, keepdim=True)\n","    std = x.std(-1, keepdim=True)\n","\n","    return self.a_2 * (x-mean) / (std+self.eps) + self.b_2"],"metadata":{"id":"2r0ZkvOXsNwS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["That is, the output of each sub-layer is LayerNorm(x+ sublayer(x))\n","\n","sublayer(x) is the function implemented by the sublayer itself.\n","\n","To ficilitate these residual connections, all sublayers in the odel, as well as the embedding layers, produce outputs of dim=512"],"metadata":{"id":"AJ-kMviosury"}},{"cell_type":"code","source":["class SublayerConnection(nn.Module) :\n","  '''\n","  A residual connection followed by a layer norm.\n","  '''\n","\n","  def __init__(self, size, dropout) :\n","    super(SublayerConnection, self).__init__()\n","    self.norm = LayerNorm\n","    self. dropout = nn.Dropout(dropout)\n","\n","  def forward(self, x) :\n","    return x + self.dropout(sublayer(self.norm(x)))"],"metadata":{"id":"TxyDB283s9tz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Each layer has two sublayers. \n","\n","The first is a multi head self att.\n","\n","The Second is a simple, position-wise fc ffn."],"metadata":{"id":"PRXaBhNMtaDv"}},{"cell_type":"code","source":["class EncoderLayer(nn.Module) :\n","  def __init__(self, size, self_attn, ff, dropout) :\n","    super(EncoderLayer,self).__init__()\n","\n","    self.size = size\n","    self.self_attn = self_attn\n","    self. ff = ff\n","    # clones  를 통해 sublayerconnection을 진행하며, 각각의 레이어는 2개\n","    self.sublayer = clones(SublayerConnection(size, dropout),2)\n","    \n","  def forward(self,x, mask) :\n","    x = self.sublayer[0](x, lambda x : self.self_attn(x,x,x,mask)) \n","    return self.sublayer[1](x, self.ff)"],"metadata":{"id":"5D354vowtino"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Decoder\n","\n","the decoder is also composed of a stack of N=6 identical layers"],"metadata":{"id":"TDszA18EuLRk"}},{"cell_type":"code","source":["class Decoder(nn.Module) :\n","  def __init__(self, layers, N) :\n","    super(Decoder,self).__init__()\n","    self.layers = clones(layer, N)\n","    self.norm = LayerNorm(layer.size)\n","\n","  def forward(self, x, memory, src_mask, tgt_mask) :\n","    for layer in self.layers :\n","      x = layer(x, memory, src_mask, tgt_mask) \n","      return self.norm(x)"],"metadata":{"id":"o3KivQAhso15"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["the decoder insets a third sublayer, which performs multi head attn oer the output of the encoder stack."],"metadata":{"id":"l0fhMrnQukTy"}},{"cell_type":"code","source":["class DecoderLayer(nn.Module) :\n","\n","  def __init__(self, size, self_attn, src_attn, ff, dropout) :\n","    super(DecoderLayer,self).__init__()\n","    self.size = size\n","    self.self_attn = self_attn\n","    self.src_attn =src_attn\n","    self.ff = ff\n","    self.sublayer = clones(SublayerConnection(size, dropout), 3)\n","\n","  def forward(self, x, memory, src_mask, tgt_mask) :\n","    m = memory\n","    x = self.sublayer[0](x, lambda x : self.self_attn(x,x,x,tgt_mask))\n","\n","    x = self.sublayer[1](x, lambda x : self.src_attn(x,m,m, src_mask))\n","\n","    return self.sublayer[2](x, self.ff)"],"metadata":{"id":"S874iMIJupjf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def subsequent_mask(size) :\n","  attn_shape = (1, size,size)\n","\n","  subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(torch.unit8)\n","\n","  return subsequent_mask == 0"],"metadata":{"id":"QQ1I47RFvJlR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def example_mask() :\n","  LS_data = pd.concat(\n","      [\n","          pd.DataFrame(\n","              {'Subsequent_mask' : subsequent_mask(20)[0][x,y].flatten(),\n","              'Window' : y,\n","               'Masking' : x\n","               }\n","          )\n","          for y in range(20)\n","          for x in range(20)\n","      ]\n","  )\n","\n","return(\n","    alt.Chart(Ls_data)\n","    .mark_rect()\n","    .properties(height = 250, width=250)\n","    .encode(\n","        alt.x('window:0'),\n","        alt.y('masking:0'),\n","        alt.color('Subsequent_mask : Q', scale = alt.Sclae(scheme= 'viridis')),\n","\n","    )\n","    .interactive()\n",")\n","\n","show_example(example_mask)"],"metadata":{"id":"VF-EVsrSvbo3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Attention\n","\n","query, key, value\n","\n","The output is computed a s a weighted sum of the values, where the weight assigned to each value i scomputed by a compatibility function of the query with the corresponding key.\n","\n","We call out particular attn 'Scaled dot product attn\".\n","\n"],"metadata":{"id":"A2NT3VYewMD_"}},{"cell_type":"code","source":["def attentino(query, key, value, mask=None, dropout=None) :\n","  d_k = query.size(-1)\n","  scores = torch.matmul(query, key.Transpose(-2, -1)) / math.sqrt(d_k)\n","\n","  if mask is not None :\n","    scores=  scores.masked_fill(mask == 0, -1e9)\n","\n","  p_attn = scores.softmax(dim=-1)\n","  \n","  if dropout is not None :\n","    p_attn = dropout(p_attn)\n","\n","  return torch.matmul(p_attn, value), p_attn"],"metadata":{"id":"6o7TfOg1uiWy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Multihead(Q,K,V) = Concat(head1,head2.....,head_h)*WO\n","\n","where head_i = Attention(QW_i^Q, Kw_i^K, VW_i^V)"],"metadata":{"id":"J8Oz45MIxGX7"}},{"cell_type":"code","source":["class MultiHeadedAttentino(nn.Module) :\n","  def __init__(self, h, d_model, dropout=0.1) :\n","    super(MultiHeadedAttention,self).__init__()\n","    assert d_model % h == 0\n","\n","    self.d_k = d_model / h\n","    self. h = h\n","    self.linears = clones(nn.Linear(d_model, d_model), 4)\n","    self.attn = None\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self, query, key, value, mask=None) :\n","    if mask is not None :\n","      mask = mask.unsqueeze(1)\n","    \n","    nbatches = query.size(0)\n","\n","    query, key, value = [\n","        lin(x).view(nbatches, -1, self.h, self.d_k).transpose(1,2)\n","        for lin, x, in zip(self.linears, (query, key, value))\n","    ]\n","\n","    x, self.attn = attention(\n","        query, key, value, mask=mask, dropout = self.dropout\n","    )\n","\n","    x  = concat(\n","        x.transpose(1,2)\n","        .contiguous()\n","        .view(nbatches, -1, self.h * self.d_k)\n","    )\n","\n","    del query\n","    del key\n","    del value\n","    return self.linears[-1](x)"],"metadata":{"id":"BAzX0swUxZFB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Position Wise FFN\n","\n","FFN(x) = max(0, xW1 + b1)*W2 + b2\n","\n","\n"," "],"metadata":{"id":"iaqjJj8fydOY"}},{"cell_type":"markdown","source":["While the linear transformations are the same across different positions, they use different parameters from layer to layer. Another way of describing this is as two convlitions with kernel size 1. The dimensionality of input and output is d_model = 512, and the inner_layer, it has dimensionality d_ff = 2048."],"metadata":{"id":"unfmO9zNyoBl"}},{"cell_type":"code","source":["class PositionwiseFF(nn.Module) :\n","\n","  def __init__(self, d_model, d_ff, dropout=0.1) :\n","    super(PositionwiseFF,self).__init__()\n","    self.w_1 = nn.Linear(d_model, d_ff)\n","    self. w_2 = nn.Linear(d_ff, d_model)\n","    self.dropout == nn.Dropout(p=dropout)\n","\n","  def forward(self, x) :\n","    return self.w_2(self.dropout(self.w_1(x).relu()))"],"metadata":{"id":"0OYKmUA6y3yR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Embeddings and Softmax\n","\n","Similariy to other sequence transduction models, we use learned embeddings to convert the input tokens and output tokens to vectors of d_model.\n","\n","We also use the usual learned linear transformation and softmax function to convert the decoder output to predicted next token probalities. In our model, we share the same weight matrix btw the two embedding layers and the pre softmax linear transformation."],"metadata":{"id":"Wt_5AIbMzTUq"}},{"cell_type":"code","source":["class Embeddings(nn.Module) :\n","  def __init__(self, d_model, vocab) :\n","    super(Embeddings,self).__init__()\n","    self.d_model = d_model\n","    self.lut = nn.Embeddings(vocab, d_model)\n","\n","  def forward(self,x) :\n","    return self.lut(x) * math.sqrt(self.d_model)"],"metadata":{"id":"O4mQo8QYzusl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Positional Encoding\n","\n","\n","Pe(pos, 2i) = sin(pos/10000^2i/d_model)\n","Pe(pos, 2i+1) = cos(pos/10000^2i/d_model)"],"metadata":{"id":"KgltERfg0Eoy"}},{"cell_type":"code","source":["class PositionalEncoding(nn.Module) :\n","  def __init__(self, d_model, dropout, max_len  = 10000) :\n","    super(PositionalEncoding,self).__init__()\n","    self.dropout = nn.Dropout(dropout)\n","\n","    pe = torch.zeros(max_len, d_model)\n","    position = torch.arange(0, max_len).unsqueeze(1)\n","    div_tern = torch.exp(\n","        torch.arange(0, d_model, 2)* - (math.log(10000) / d_model)\n","    )\n","\n","    pe[:, 0::2] = torch.sin(position * div_tern)\n","    pe[:, 1::2] = torch.cos(position * div_term)\n","\n","    pe = pe.unsqueeze(0)\n","    self.register_buffer('pe',pe)\n","\n","  def forward(self, x) :\n","    x = x + self.pe[: , : x.size(1)].requres_grad_(False)\n","    return self.dropout(x)"],"metadata":{"id":"AcJDfn5b0Osf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Full model"],"metadata":{"id":"VpkrvKHk07lw"}},{"cell_type":"code","source":["def make_model (src_vocab, tgt_vocab, N=6, d_model = 512, d_ff = 2048, h=8, dropout=0.1) :\n","\n","  c =copy.deepcopy\n","  attn = MultiHeadedAttn(h, model) \n","  ff = PositionwiseFF(d_model, d_ff, dropout)\n","  position = PositionalEncoding(d_model, dropout)\n","\n","  model = EncoderDecoder(\n","      Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n","      Decoder(DecoderLayer(d_model, c(attn), , c(attn), c(ff), dropout), N),\n","      \n","      nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n","      nn.Sequential(Embeddings(d_model, tgt_vocab, c(position))),\n","      Generator(d_model, tgt_vocab)\n","  )\n","\n","  for p in model.parameters() :\n","    if p.dim() >1 :\n","      nn.init.xavier_uniform(_p)\n","  return model"],"metadata":{"id":"Cq6ZzNsL025K"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Model Training"],"metadata":{"id":"PuiUpha8-Pwh"}},{"cell_type":"markdown","source":["##Batches and Masking"],"metadata":{"id":"kIrYt2Y8-TAa"}},{"cell_type":"code","source":["class batch :\n","\n","  def __init__(self, src, tgt=None, pad=2) :    # 2 == blank\n","    self.src = src\n","    self.src_mask = (src != pad).unsqueeze(-2)\n","    if tgt is not None :\n","      self.tgt = tgt[:, :-1]\n","      self.tgt_y = tgt[:, 1:]\n","      self.tgt_mask = self.make_std_mask(self.tgt, pad)\n","      self.ntokens = (self.tgt_y != pad).data.sum()\n","\n","  @staticmethod\n","  def make_std_mask(tgt, pad) :\n","    tgt_mask = (tgt != pad).unsqueeze(-2)\n","    tgt_mask = tgt_mask & subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data)\n","\n","    return tgt_mask"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136},"id":"y9466xoz18SI","executionInfo":{"status":"error","timestamp":1680237767580,"user_tz":-540,"elapsed":16,"user":{"displayName":"김시윤","userId":"10463797081079810917"}},"outputId":"7aec80ee-b575-47d5-f760-2e77fcb8233f"},"execution_count":1,"outputs":[{"output_type":"error","ename":"IndentationError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-931de1f0034b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    class batch :\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"]}]},{"cell_type":"markdown","source":["##Trainig Loop"],"metadata":{"id":"FQ0XASHC_Bru"}},{"cell_type":"code","source":["class TrainState :\n","  '''Track # steps, examples, and tokens processed'''\n","\n","  step : int = 0\n","  accum_step : int = 0\n","  sample : int = 0\n","  tokens : int = 0"],"metadata":{"id":"Q4LoN2E8-Vgr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def run_epoch(data_iter, model, loss_compute, optimizer, scheduler, mode='train', accum_iter=1, train_state = TrainState()) :\n","  '''Train a single epoch'''\n","  start = time.time()\n","  total_tokens = 0\n","  totla_loss = 0\n","  tokens = 0\n","  n_accum = 0\n","\n","  for i,batch in enumerate(data_iter) :\n","    out = model.forward(batch.src, batch.tgt, batch.src_mask, batch_tgt_mask)\n","    loss, loss_node = loss_compute(out, bath.tgt_y, batch.ntokens)\n","\n","    # loss_node = loss_node / accum_iter\n","    if mode == 'train' or mode == 'train+log' :\n","      loss_node.backward()\n","      train_state.step +=1\n","      train_state.smaples += batch.src.shape[0]\n","      train_state.tokens += bathc.ntokens\n","      if i % accum_iter == 0 :\n","        optimizer.step()\n","        optimizer.zero_grad(set_to_none = True)\n","        n_accum+=1\n","        train_state.accum_iter +=1\n","      \n","      scheduler.step()\n","    \n","    total_loss += loss\n","    total_tokens += bathc.ntokens\n","    tokens += bathc.ntokens\n","\n","    if i % 40 == 1 and ( mode == 'train' or mode == 'train+log') :\n","      lr = optimizer.param_groups[0]['lr']\n","      elapsed = time.time - start\n","\n","      print(\n","          'epoch step : %6d | accumulatino step : %3d | loss : %6.2f' + '| tokens  / sec : %7.1f |'\n","\n","      )\n","      start = time.time()\n","      tokens = 0\n","\n","    del loss\n","    del loss_node\n","  return total_loss / total_token, train_state"],"metadata":{"id":"Av9_QX5E_M5X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Optmizer\n","\n","we used the adam with b1 = 0.9, b2= 0.98, ϵ=1e-.\n","\n","lrate = d_model^-0.5 * min(step_num^0.5, step_num.warmup_steps^-1.5)\n","\n","also, used warmup_steps was 4000."],"metadata":{"id":"8Ap7XiNeAmuz"}},{"cell_type":"code","source":["def rate(step, model_size, factor, warmup) :\n","  '''\n","  we have to default the step to 1 for lambdaLR fucntion to avoid zero raising to negative power.\n","  '''\n","\n","  if step == 0 :\n","    step =1\n","  return factgor * (model_size ** (-0.5) * min(step **(-0.5), step * warmup ** (-1.5)))\n","\n","  "],"metadata":{"id":"RIQkhpL9A7vm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def examples_learning_schedule() :\n","  opts = [ \n","      [512,1,4000], #example1\n","      [512,1,8000], #example2\n","      [245,1,4000]  #example3\n","  ]\n","\n","  dummy_model = torch.nn.Linear(1,1)\n","  learning_rates = []\n","\n","  # we have 3examples in opts list.\n","\n","  for idx, example in enumerate(opts) :\n","    optimizer = torch.optim.Adam(dummy_model.parameters(), lr=1, betas=(0.9,0.98), eps=1e-9)\n","    lr_scheduler = LambdaLR(optimizer= optimizer, lr_lambda = lambda step: rate(stpe, *example))\n","\n","    temp = []\n","\n","    for step in range(20000) :\n","      temp.append(optimizer.parma_groups[0]['lr'])\n","      optimizer.step()\n","      lr_scheduler.step()\n","    learning_rates.append(temp)\n","\n","  learning_rates = torch.tensor(learning_rates)\n","\n","  # Enable altair to handle more than 5000 rows\n","  alt.data_transformers.disable_max_rows()\n","\n","  opts_data = pd.concat(\n","      [\n","          pd.DataFrame(\n","              {\n","              'learning rate' : learning_rates[warmup_idx, :],\n","              'model_size : warmup' : [\"512:4000\", \"512:8000\", \"256:4000\"][warmup_idx],\n","              'step' : range(20000)\n","         }\n","      )\n","          for warmpup_idx in [0,1,2]\n","    ]\n","  )\n","\n","return (\n","    alt.Chart(opts_data)\n","    .mark_line()\n","    .properties(width=600)\n","    .encode(x=  'spte', y='learning rate', color = 'model_size : warmup:N')\n","    .interactive()\n",")"],"metadata":{"id":"MfWhfLW4BMOl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Regularization\n"],"metadata":{"id":"QNYPvGaYClQz"}},{"cell_type":"markdown","source":["###Label Smoothing\n","\n","we implement label smoothing using the KL div loss."],"metadata":{"id":"smD8ny3cCm4O"}},{"cell_type":"code","source":["class LabelSmoothing(nn.Module) :\n","  def __init__(self, size, padding_idx, smoothing=0.1) :\n","    super(LabelSmoothing,self).__init__()\n","    self.criterion = nn.KLDivLoss(reduction='sum')\n","    self.padding_idx = padding_idx\n","    self.confidence = 1 - smoothing\n","    self.smoothing = smoothing\n","    self.size = size\n","    self.true_dist = None\n","\n","  \n","  def forward(self, x, target) :\n","    assert x.size(1) == self.size\n","    true_dist = x.data.clone()\n","    true.dist_fill_(self.smoothing / (self.size - 2))\n","    true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n","    true_dist[:, self.padding_idx] = 0\n","    mask = torch.nonzero(target.data == self.padding_idx)\n","\n","    if mask_dim() > 0 :\n","      true_dist.index_fill(0, mask.squeeze(), 0.0)\n","    self.true_dist = true_dist\n","    return self.criterion(x, true_dist.clone().detach())"],"metadata":{"id":"k3qdcPnRCtsm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Label smoothing actually starts to penalize the model if it gets very confident about a given choice."],"metadata":{"id":"ErTSI_4bDeDP"}},{"cell_type":"code","source":["def loss(x,crit) :\n","  d = x +3 * 1\n","  predict = torch.FloatTensor([[0, x / d, 1 / d, 1 / d, 1 / d]])\n","  return crit(predict.log(), torch.LongTensor([1])).data\n","\n","def penalization_visualization() :\n","  crit = LabelSmoothing(5,0,0.1)\n","  loss_data = pd.DataFrame({\n","      'loss' : [loss(x,crit) for x in range( 1,100)],\n","      'steps' : list(range(99))}\n","  ).astype('float')\n","\n","  return(\n","      alt.Chart(loss_data).\n","      mark_line()\n","      .properties(width=350)\n","      .encode(\n","          x= ' steps',\n","          y=  'loss',\n","\n","      )\n","      .interactive()\n","  )\n","\n","show_examples(penalization_visualization)"],"metadata":{"id":"lSlwq8g8Dh64"},"execution_count":null,"outputs":[]}]}