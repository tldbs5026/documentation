{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMhHYUSkCDY/8CQ31RurNF+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1256e252e00542319055721601cc0a00":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4c7ac72dac4a44f28d4a91ff402821d7","IPY_MODEL_12e2e05b7c14459da5cb1bfc59ecdc0e","IPY_MODEL_ffbbfbaaeb134a478904cb39ccc17f3b"],"layout":"IPY_MODEL_7314a47bdb794a6888f5a04bb971b108"}},"4c7ac72dac4a44f28d4a91ff402821d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf6a4600879241f8ae99f854e12c2f48","placeholder":"​","style":"IPY_MODEL_9ae680d487294edd8ad1a2c61183aa87","value":"100%"}},"12e2e05b7c14459da5cb1bfc59ecdc0e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c88b81ee3fb4b1f9d86c9618e5593f6","max":170498071,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d305e5ffda6b43edbd9f3bc523bb4479","value":170498071}},"ffbbfbaaeb134a478904cb39ccc17f3b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f06136df67334d28ad1d7a4088d5f30d","placeholder":"​","style":"IPY_MODEL_adb3aeda836c4a8cbd968a8f7a65683f","value":" 170498071/170498071 [00:02&lt;00:00, 85316749.71it/s]"}},"7314a47bdb794a6888f5a04bb971b108":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf6a4600879241f8ae99f854e12c2f48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ae680d487294edd8ad1a2c61183aa87":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c88b81ee3fb4b1f9d86c9618e5593f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d305e5ffda6b43edbd9f3bc523bb4479":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f06136df67334d28ad1d7a4088d5f30d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"adb3aeda836c4a8cbd968a8f7a65683f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"mSaHVOVQ9UFc","executionInfo":{"status":"ok","timestamp":1667520106310,"user_tz":-540,"elapsed":3786,"user":{"displayName":"김시윤","userId":"10463797081079810917"}}},"outputs":[],"source":["import torch\n","import torchvision\n","import torchvision.transforms as tr\n","#데이터 불러오며 전처리를 할 수 있게\n","from torch.utils.data import DataLoader, Dataset\n","#batchsize 형태로 변환가능 / Dataset은 튜닝\n","import numpy as np"]},{"cell_type":"markdown","source":["#1. 파이토치 제공 데이터 사용"],"metadata":{"id":"Neq9yATJNYRN"}},{"cell_type":"code","source":["transf = tr.Compose([tr.Resize(8), tr.ToTensor()])\n","#8x8로 변환후 tensor로 변환\n","\n","# #Trnasforms on PIL Image\n","# pad, grayscale, randomcrop, normilize...\n","# transforms on torch.*Tensor - tensro importtorchvision.transforms.ToPILImage(mode=None)\n","\n","#이 중 필요한 전처리 작업compose안에"],"metadata":{"id":"zDxT4pZTODin","executionInfo":{"status":"ok","timestamp":1667520106312,"user_tz":-540,"elapsed":11,"user":{"displayName":"김시윤","userId":"10463797081079810917"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["trainset=torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transf)\n","testset=torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transf)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":103,"referenced_widgets":["1256e252e00542319055721601cc0a00","4c7ac72dac4a44f28d4a91ff402821d7","12e2e05b7c14459da5cb1bfc59ecdc0e","ffbbfbaaeb134a478904cb39ccc17f3b","7314a47bdb794a6888f5a04bb971b108","cf6a4600879241f8ae99f854e12c2f48","9ae680d487294edd8ad1a2c61183aa87","0c88b81ee3fb4b1f9d86c9618e5593f6","d305e5ffda6b43edbd9f3bc523bb4479","f06136df67334d28ad1d7a4088d5f30d","adb3aeda836c4a8cbd968a8f7a65683f"]},"id":"b8vKaydINdZ1","executionInfo":{"status":"ok","timestamp":1667520113640,"user_tz":-540,"elapsed":6317,"user":{"displayName":"김시윤","userId":"10463797081079810917"}},"outputId":"792e1afa-5673-46f6-ec76-1823418cb2d4"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/170498071 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1256e252e00542319055721601cc0a00"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["trainset[0][0].size()\n","#tuple 형태로 저장, 이 경우는 3channel의 8x8 tensor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9eR0bWjJOoVE","executionInfo":{"status":"ok","timestamp":1667520114055,"user_tz":-540,"elapsed":422,"user":{"displayName":"김시윤","userId":"10463797081079810917"}},"outputId":"15033228-5237-4f33-a643-4dfab9d43dec"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 8, 8])"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["trainloader = DataLoader(trainset, batch_size=50, shuffle=True, num_workers=2)\n","testloader = DataLoader (testset, batch_size=50, shuffle=True, num_workers=2)\n","#num_workers similar to n_jobs\n"],"metadata":{"id":"95DeINF7O51E","executionInfo":{"status":"ok","timestamp":1667520131111,"user_tz":-540,"elapsed":359,"user":{"displayName":"김시윤","userId":"10463797081079810917"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["len(trainloader)\n","#batchsize50개가 1000개있음을 의미"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xzBrrjbsPYZV","executionInfo":{"status":"ok","timestamp":1667520134543,"user_tz":-540,"elapsed":378,"user":{"displayName":"김시윤","userId":"10463797081079810917"}},"outputId":"87b5169f-5903-4887-bc8c-fec5a06fd271"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1000"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["#실제 값을 확인하고 싶으면\n","dataiter = iter(trainloader)\n","images, labels = dataiter.next()\n"],"metadata":{"id":"7cG5EqzoPiHA","executionInfo":{"status":"ok","timestamp":1667520149754,"user_tz":-540,"elapsed":343,"user":{"displayName":"김시윤","userId":"10463797081079810917"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["images.size()\n","#batch_size is 50, 3channel, 8x8"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xAyY3s4nPtB7","executionInfo":{"status":"ok","timestamp":1667520155858,"user_tz":-540,"elapsed":367,"user":{"displayName":"김시윤","userId":"10463797081079810917"}},"outputId":"28d31776-ae9c-4ad2-83ac-f1408bc2dc68"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([50, 3, 8, 8])"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["##transforms --> torchvision.datasets --> DataLoader"],"metadata":{"id":"bhSexN1pPR7Q"}},{"cell_type":"markdown","source":["#2. 같은 클래스 별 폴더 이미지 데이터 이용"],"metadata":{"id":"bu6UP9ecNZpV"}},{"cell_type":"code","source":["#ex) ./class/tiger  & ./class/lion\n","\n","transf = tr.Compose([tr.Resize(16), tr.ToTensor()])\n","#전처리 방법 정의\n","trainset = torchvision.datasets.ImageFolder(root='./class', transform=transf)\n","#class 폴더 안의 image들을 searching 후 각각 다른 폴더에 대해 label 및 전처리\n","trainloader = DataLoader(trainset, batch_size=1, shuffle=False, num_workers=2)\n","print(len(trainloader))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":390},"id":"JnlqUW2JP8I3","executionInfo":{"status":"error","timestamp":1667359346701,"user_tz":-540,"elapsed":441,"user":{"displayName":"김시윤","userId":"10463797081079810917"}},"outputId":"4501158f-9e20-432d-86f4-67d3d7242e2a"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-17ca5ed4b366>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtransf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#전처리 방법 정의\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./class'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#class 폴더 안의 image들을 searching 후 각각 다른 폴더에 대해 label 및 전처리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtrainloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0mis_valid_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_valid_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         )\n\u001b[1;32m    318\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    143\u001b[0m     ) -> None:\n\u001b[1;32m    144\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \"\"\"\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './class'"]}]},{"cell_type":"code","source":["trainset[0][0].size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ostdBa__Qru1","executionInfo":{"status":"ok","timestamp":1667359354236,"user_tz":-540,"elapsed":304,"user":{"displayName":"김시윤","userId":"10463797081079810917"}},"outputId":"edbdeffb-fd4c-4538-cbf9-48e16d06ba1e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 8, 8])"]},"metadata":{},"execution_count":47}]},{"cell_type":"markdown","source":["#3. 개인 데이터 사용 (2types)"],"metadata":{"id":"v177_VVfNbQi"}},{"cell_type":"code","source":["#import preprocessing\n","\n","train_images = np.random.randint(256, size=(20,32,32,3))\n","train_labels = np.random.randint(2, size=(20,1))\n","\n","#preprocessing\n","#train_images, train_labels = preprocessing(train_images, train_labels)\n","\n","print(train_images.shape, train_labels.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oL4G5CVyQxwA","executionInfo":{"status":"ok","timestamp":1667359355558,"user_tz":-540,"elapsed":2,"user":{"displayName":"김시윤","userId":"10463797081079810917"}},"outputId":"1a1ac53e-b92a-4848-f997-4e721cb5b01b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(20, 32, 32, 3) (20, 1)\n"]}]},{"cell_type":"code","source":["#Dataset의 상속을 받을 class의 기본적인 형식\n","#\n","\n","class TensorData(Dataset) :\n","  def __init__(self, x_data,y_data) :\n","    #외부 데이터를 쓸경우 이런식으로, 내부 데이터를 쓸경우는 self만\n","    self.x_data = torch.FloatTensor(x_data)\n","    #들어온 데이터를 tensor로 변환\n","    self.x_data = self.x_data.permute(0,3,1,2)    #이미지 개수, 채널 수, 이미지 너비 및 높이\n","    #즉, train_image.shape의 값은 (20,3,32,32)가 됨.\n","    # train_images의 순서인 batch_size, channel, w*h를 변경\n","    self.y_data = torch.LongTensor(y_data)\n","    #y또한 tensor로 변경 / torch.후에 long/float등으로 구체적으로 변경 가능\n","    self.len = self.y_data.shape[0]\n","\n","  def __getitem__(self, index) :\n","    return self.x_data[index], self.y_data[index]\n","    #x 와 y를 tuple의 형태로 변환\n","\n","  def __len__(self) :\n","    return self.len"],"metadata":{"id":"J1Pq4_LtRLt5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data = TensorData(train_images, train_labels)\n","train_loader = DataLoader(train_data, batch_size=10, shuffle=True)"],"metadata":{"id":"PoZn8aK7SdXJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data[0][0].size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q3A0454ASmJS","executionInfo":{"status":"ok","timestamp":1667359361425,"user_tz":-540,"elapsed":6,"user":{"displayName":"김시윤","userId":"10463797081079810917"}},"outputId":"b5fdcd07-dbbc-456a-cafe-036599294946"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 32, 32])"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["dataiter = iter(train_loader)\n","images, labels = dataiter.next()"],"metadata":{"id":"5f5jOzY1Sr0k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["images.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WEoQlAhwSwi5","executionInfo":{"status":"ok","timestamp":1667359363780,"user_tz":-540,"elapsed":3,"user":{"displayName":"김시윤","userId":"10463797081079810917"}},"outputId":"51c6e336-85ff-422e-c053-808ba2f58d8b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([10, 3, 32, 32])"]},"metadata":{},"execution_count":53}]},{"cell_type":"markdown","source":["torchvision.datasets.ImageFolder를 안쓰는 이유?\n","\n","1. 폴더 정리를 못할 경우\n","- 다른 작업과 공용으로 사용\n","- 혹은 SQL같은 곳에서 넘어오는 경우\n","\n","2. pytorch에서 제공하는 transform의 종류가 제한적임\n","- 따라서 python의 preprocessing을 거친 후 Tensor로 추가 변환을 하는 것이 다양한 경우 가능함"],"metadata":{"id":"JFUHbvPuS6OC"}},{"cell_type":"markdown","source":["#4. pytorch로만 전처리"],"metadata":{"id":"Q9mUin8QTvEY"}},{"cell_type":"code","source":["####기본 형태\n","\n","#########from torch.utils.data import Dataset\n","\n","# class MyDataset(Dataset) :\n","#   def __init__(self) : 데이터를 가져오고 전처리 방식을 결정\n","#   def __getitem__(self, index) : transform에 따라 형식을 np or tesor로 변환 후 데이터를 tuple로 묶음\n","#   def __len__(self) : 길이\n","\n","#추가\n","#class ToTensor() : Tensor로 변환\n","#class LinearTensor() : 선형변환을 주려면 어떤 방식으로 변환을 할 것인가"],"metadata":{"id":"MBnvy4zDTxX8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MyDataset(Dataset) :\n","\n","  def __init__(self, x_data, y_data, transform=None) :\n","\n","    self.x_data = x_data\n","    self.y_data = y_data\n","    self.transform=transform\n","    self.len = len(y_data)\n","\n","  def __getitem__ (self, index) :\n","    sample = self.x_data[index], self.y_data[index]\n","#tuple형태로 x 와 y를 변환\n","    if self.transform :\n","      sample = self.transform(sample)\n","      #tuple값을 반환하기 전 transform진행\n","    return sample\n","    #transform이 None이면 numpy로 반환, 만약 한다면 tensor로 반환\n","  \n","  def __len__(self) :\n","    return self.len\n","\n","\n","class ToTensor :\n","  def __call__(self, sample) :\n","    inputs, labels = sample\n","    inputs = torch.FloatTensor(inputs)\n","    inputs = inputs.permute(2,0,1)\n","    return inputs, torch.LongTensor(labels)\n","    #나가는 값이 tensor\n","\n","\n","class LinearTensor :\n","  def __init__(self, slope=1, bias=0) :\n","    self.slope = slope\n","    self.bias = bias\n","\n","  def __call__ (self, sample) :\n","    inputs, labels = sample\n","    inputs = self.slope*inputs + self.bias\n","    return inputs, labels"],"metadata":{"id":"EPn-kXniUpDJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trans = tr.Compose([ToTensor(), LinearTensor(2,5)])\n","#linear는 2x+5의 형식\n","ds1 = MyDataset(train_images, train_labels, transform=trans)\n","train_loader1 = DataLoader(ds1, batch_size=10, shuffle=True)"],"metadata":{"id":"CaYIQXbIVw_8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["first_data = ds1[0]\n","features, labels = first_data\n","print(type(features), type(labels))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CWN7zVORWwBE","executionInfo":{"status":"ok","timestamp":1667359446876,"user_tz":-540,"elapsed":2,"user":{"displayName":"김시윤","userId":"10463797081079810917"}},"outputId":"6cb83222-87aa-4adf-bbb8-a6031ccf65d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torch.Tensor'> <class 'torch.Tensor'>\n"]}]},{"cell_type":"code","source":["dataiter1 = iter(train_loader1)\n","images1,labels1=dataiter1.next()"],"metadata":{"id":"SXTGR6IEXlVt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["images1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jY4lPgPfXsbd","executionInfo":{"status":"ok","timestamp":1667359496598,"user_tz":-540,"elapsed":4,"user":{"displayName":"김시윤","userId":"10463797081079810917"}},"outputId":"ad519599-3d68-4c0d-a443-285b3616c8cd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[[389.,  55., 493.,  ..., 111., 473., 441.],\n","          [159.,  67.,  71.,  ..., 327., 501., 485.],\n","          [  5., 273., 203.,  ..., 209., 397., 169.],\n","          ...,\n","          [375., 211., 431.,  ..., 419., 299., 313.],\n","          [451., 217., 423.,  ..., 161., 353., 175.],\n","          [471., 123., 403.,  ...,  25., 231., 129.]],\n","\n","         [[ 25., 223., 319.,  ..., 489., 347.,  41.],\n","          [425.,  69., 501.,  ..., 431., 409., 339.],\n","          [501., 511., 457.,  ..., 189., 337., 489.],\n","          ...,\n","          [115., 221., 451.,  ..., 393., 373., 419.],\n","          [443., 231., 179.,  ..., 515., 455., 217.],\n","          [473., 473.,  31.,  ..., 339., 409., 121.]],\n","\n","         [[507., 241., 149.,  ..., 261., 375., 255.],\n","          [ 31., 391., 259.,  ..., 179., 125., 345.],\n","          [221., 229., 495.,  ..., 195., 325., 483.],\n","          ...,\n","          [377., 157., 513.,  ...,   7.,  39.,  79.],\n","          [121., 485., 155.,  ..., 171., 365., 161.],\n","          [ 25.,  43., 505.,  ...,  79., 147., 489.]]],\n","\n","\n","        [[[163., 111., 253.,  ..., 135., 309., 261.],\n","          [441.,  37., 237.,  ..., 101., 163., 361.],\n","          [  9., 417., 185.,  ..., 331., 129., 411.],\n","          ...,\n","          [501., 211., 301.,  ..., 299., 505., 479.],\n","          [149.,  23.,  71.,  ..., 115., 361., 127.],\n","          [153., 413., 349.,  ..., 405.,  47.,  63.]],\n","\n","         [[143.,  71., 513.,  ..., 243., 195., 123.],\n","          [403., 513.,  93.,  ..., 287., 111., 367.],\n","          [431., 129., 151.,  ..., 289., 505., 331.],\n","          ...,\n","          [227., 503.,  81.,  ..., 347., 425., 243.],\n","          [143., 383.,  79.,  ..., 133., 481., 117.],\n","          [247., 257.,  13.,  ..., 511., 461.,  43.]],\n","\n","         [[385.,  61., 135.,  ..., 507.,  59., 337.],\n","          [253.,  37., 391.,  ..., 123., 325.,  85.],\n","          [269., 307., 325.,  ..., 151., 117.,  19.],\n","          ...,\n","          [ 85., 415., 351.,  ...,  13., 365.,  77.],\n","          [247.,  87., 391.,  ..., 163., 175., 391.],\n","          [255., 325., 507.,  ..., 373., 427., 259.]]],\n","\n","\n","        [[[139.,  81., 507.,  ..., 409., 227., 427.],\n","          [289., 259., 443.,  ..., 175., 343., 387.],\n","          [113.,  19.,   7.,  ..., 449., 235., 205.],\n","          ...,\n","          [285., 475.,  63.,  ..., 279.,  83., 471.],\n","          [441., 213.,  59.,  ..., 107.,  83., 117.],\n","          [207., 441., 145.,  ..., 463., 363., 139.]],\n","\n","         [[451., 513., 287.,  ..., 449., 215.,   9.],\n","          [441., 469., 495.,  ..., 105., 413., 275.],\n","          [303., 115., 179.,  ..., 473., 469., 255.],\n","          ...,\n","          [223., 189.,  23.,  ..., 149.,   9., 227.],\n","          [ 61.,  71., 497.,  ..., 109., 319., 363.],\n","          [353., 169., 425.,  ..., 197.,  11., 475.]],\n","\n","         [[407., 447.,  55.,  ...,  73., 221., 357.],\n","          [335., 461., 461.,  ...,  65., 379., 129.],\n","          [ 51., 291., 111.,  ..., 433., 439., 455.],\n","          ...,\n","          [207.,  27., 249.,  ...,  41., 399., 449.],\n","          [361., 351., 297.,  ..., 491., 455., 227.],\n","          [ 11., 119., 275.,  ..., 473., 285., 167.]]],\n","\n","\n","        ...,\n","\n","\n","        [[[373., 321.,  81.,  ..., 223., 113.,  91.],\n","          [459., 449., 183.,  ..., 383., 375., 489.],\n","          [325., 233., 155.,  ..., 243., 417., 213.],\n","          ...,\n","          [473.,  39., 257.,  ..., 289., 381., 431.],\n","          [353.,  69., 389.,  ..., 177., 491., 143.],\n","          [ 81., 409., 469.,  ..., 407., 173., 251.]],\n","\n","         [[327., 145., 499.,  ..., 483., 377.,  11.],\n","          [403., 133., 449.,  ..., 515., 299., 433.],\n","          [375., 223., 487.,  ...,  27.,  75., 143.],\n","          ...,\n","          [207., 483., 161.,  ...,  43., 341., 425.],\n","          [301., 249., 143.,  ..., 153., 239., 303.],\n","          [359., 317., 357.,  ..., 465., 425., 423.]],\n","\n","         [[ 79., 419.,  49.,  ..., 481., 451., 215.],\n","          [245., 107., 481.,  ..., 513., 341.,  81.],\n","          [327.,   7.,  99.,  ...,  65., 315., 197.],\n","          ...,\n","          [441., 267.,  97.,  ...,  99., 159., 485.],\n","          [369., 343., 413.,  ..., 365., 279., 365.],\n","          [ 11., 325., 195.,  ...,  77.,  47.,  15.]]],\n","\n","\n","        [[[465., 187.,  31.,  ..., 115., 489., 107.],\n","          [449., 511., 231.,  ..., 233., 165., 341.],\n","          [201., 181., 319.,  ..., 443., 253., 127.],\n","          ...,\n","          [339., 129., 187.,  ..., 459., 147., 437.],\n","          [503.,  73., 513.,  ...,  27., 313., 303.],\n","          [261., 289., 219.,  ..., 317., 193., 211.]],\n","\n","         [[283.,  45.,  95.,  ..., 437.,   5., 445.],\n","          [379., 285., 203.,  ..., 189., 207., 183.],\n","          [  5., 163., 107.,  ..., 463., 289., 213.],\n","          ...,\n","          [ 61., 275., 235.,  ...,  15., 495., 287.],\n","          [487., 283., 245.,  ..., 481., 143., 305.],\n","          [113., 449.,  39.,  ...,  45.,  43., 463.]],\n","\n","         [[371.,   9., 507.,  ...,  27.,  51., 225.],\n","          [281., 463.,   9.,  ..., 399., 113.,  39.],\n","          [385., 293., 279.,  ..., 289.,  71.,   7.],\n","          ...,\n","          [427., 127., 443.,  ..., 351., 187., 327.],\n","          [ 19., 167., 307.,  ..., 137., 193., 161.],\n","          [127., 489., 259.,  ..., 413., 461., 323.]]],\n","\n","\n","        [[[373.,  53., 201.,  ..., 167., 197., 465.],\n","          [255., 379., 271.,  ...,  89., 215.,  57.],\n","          [245., 433., 165.,  ...,  85.,  41., 229.],\n","          ...,\n","          [195.,  65., 375.,  ..., 183., 447., 173.],\n","          [201., 429.,  17.,  ..., 215., 105., 149.],\n","          [ 61., 263., 491.,  ..., 277., 255.,  79.]],\n","\n","         [[327., 139., 385.,  ..., 485., 397., 319.],\n","          [ 59., 411.,  17.,  ..., 197., 295.,  67.],\n","          [385., 309., 419.,  ..., 291., 275., 293.],\n","          ...,\n","          [447., 163., 115.,  ..., 349., 109., 261.],\n","          [ 17., 487., 189.,  ...,  35., 103., 467.],\n","          [385., 229., 149.,  ...,  85., 333., 257.]],\n","\n","         [[445., 155., 375.,  ..., 235., 477., 347.],\n","          [239., 377., 427.,  ..., 187., 363., 119.],\n","          [137., 313., 471.,  ..., 253., 379., 197.],\n","          ...,\n","          [485., 357.,  77.,  ..., 487., 161., 265.],\n","          [433., 413., 171.,  ..., 511., 401., 137.],\n","          [453., 383., 249.,  ...,  75., 461., 205.]]]])"]},"metadata":{},"execution_count":62}]},{"cell_type":"markdown","source":["trans = tr.Compose([tr.ToTensor()])\n","이거 쓰면 안되냐?\n","\n","- class를 사용하여 받은 데이터는 numpy임\n","- tr.ToTensor()로 받는 형식은 PIL Image를 바탕으로 사용하기 때문에 타입이 달라서 실행이 안됨"],"metadata":{"id":"BV-gLWTHX89V"}},{"cell_type":"markdown","source":["PIL을 사용하는 방법"],"metadata":{"id":"LwvcdrOKYVv8"}},{"cell_type":"code","source":["class MyDataset(Dataset) :\n","\n","  def __init__(self, x_data, y_data, transform=None) :\n","\n","    self.x_data = x_data\n","    self.y_data = y_data\n","    self.transform=transform\n","    self.len = len(y_data)\n","\n","  def __getitem__ (self, index) :\n","    sample = self.x_data[index], self.y_data[index]\n","#tuple형태로 x 와 y를 변환\n","    if self.transform :\n","      sample = self.transform(sample)\n","      #tuple값을 반환하기 전 transform진행\n","    return sample\n","    #transform이 None이면 numpy로 반환, 만약 한다면 tensor로 반환\n","  \n","  def __len__(self) :\n","    return self.len\n","\n","class MyTransform :\n","  def __init__(self,sample) :\n","    inputs = labels, sample\n","    inputs = torch.FloatTensor(inputs)\n","    inputs = inputs.permute(2,0,1)\n","    labels = torch.FloatTensor(labels)\n","\n","    transf = tr.Compose([tr.ToPILImage(), tr.Resize(128), tr.ToTensor(), tr.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n","    final_output = transf(inputs)\n","\n","    return final_output, labels"],"metadata":{"id":"WfC2J-T1YXwg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ds2 = MyDataset(train_images, train_labels, transform=MyTransform())\n","train_loader2 = DataLoader(ds2, batch_size=10, shuffle=True)"],"metadata":{"id":"zyZWatnMOtVG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["first_data = ds2[0]\n","feature, labels = first_data\n","print(type(features), type(lables))"],"metadata":{"id":"JZIiC6xaO250"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataiter2 = iter(train_loader2)\n","images2, labels2 = dataiter2.next()"],"metadata":{"id":"DVRXCKa8PC0o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image2.size()"],"metadata":{"id":"wsjjAJOiPKS0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image2"],"metadata":{"id":"kb3gsJwEPLsX"},"execution_count":null,"outputs":[]}]}