{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOlBGNQKTS+49vZO6Gf1k0U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["https://deep-learning-study.tistory.com/376"],"metadata":{"id":"DSH0if4zfTvE"}},{"cell_type":"markdown","source":["https://github.com/dansuh17/alexnet-pytorch/blob/master/model.py\n","\n","original : https://dl.acm.org/doi/pdf/10.1145/3065386"],"metadata":{"id":"Rw9rWMDSgc8o"}},{"cell_type":"markdown","source":["\n","ImageNet Classification With Deep Convolutional Neural Networks"],"metadata":{"id":"tSFdcKD8mfKy"}},{"cell_type":"markdown","source":["CNN 구조의 GPU 구현 및 dropout 적용\n","\n"],"metadata":{"id":"QwJXmSffmzyh"}},{"cell_type":"markdown","source":["*dropout\n","- 통계 모델을 정규화하는 방법에 대해 가중치의 크기(L2 norm)을 패널티로 사용하여, 가중치 값을 강제로 축소.\n","\n","딥 뉴럴 네트워크\n","- 각 특성을 독립적으로 보는 제약이 없기 때문에 편향 분산(bias-variance) 스펙트럼에서의 낮은 편향 및 높은 분산의 현상을 보임.\n","- 특성의 개수가 적은 경우에도 오버피팅될 가능성이 높음\n","\n","--> 가중치 감쇠(weight decay) 및 l2 normalization을 통해 단항 함수를 사용해서 모델을 학습시키며 간단함을 유도\n","\n","- 편향을 추가하지 않으면서 노이즈를 추가\n",": ϵ∼N(0,σ2)  노이즈를 입력에 더한 후  x′=x+ϵ  이 것을 학습 데이터로 사용\n","\n","즉, 드롭아웃은 마지막 결과를 계산하기 위해 사용되는 연산의 몇몇 뉴런을 누락시킴.\n"],"metadata":{"id":"KiqmRNWRpsLU"}},{"cell_type":"markdown","source":["사용한 데이터 : ImageNet dataset\n","- 1000 images with 1000 categories"],"metadata":{"id":"63tOdh1cpvbn"}},{"cell_type":"markdown","source":["#data preprocessing\n","\n","1. 이미지 크기를 256*256\n","- resize방법은 이미지에서 짧은 쪽을 256으로 고정 후 중앙 부분을 256x256으로 crop\n","2. 각 이미지의 pixel에 training set의 평균 뺴기\n","- 각 이미지의 pixel에 training set의 평균을 빼서 normalize\n"],"metadata":{"id":"JANhnnnqp4RW"}},{"cell_type":"markdown","source":["#AlexNet Architecture"],"metadata":{"id":"p9UBAdCQqYeT"}},{"cell_type":"markdown","source":["- AlexNet은 일부가 max-pooling layer가 적용된 5개의 convolutional layer와 3개의 fully-connected layer로 구성\n","\n","- [Input layer- Conv1 - MaxPool1 - Norm1 - Conv2 - MaxPool2 - Norm2 - Conv3 - Conv4 - Conv5 - Maxpool3 - FC1 - FC2 -Output layer]\n","\n","1. Input layer\n",": 227x227x3\n","\n","\n","2. Conv1\n",": 96 kernels, 11x11, stride=4, padding=0\n","- input : 224x224x3\n","- output : 55x55x96\n","\n","3. MaxPool1\n",": 3x3 kernels, stride=2\n","- input : 55x55x96\n","- output : 27x27x96\n","\n","4. Norm1\n",": LRN을 사용한 normalization layer\n","- input : 27x27x96\n","- output : 27x27x96\n","\n","5. Conv2\n",": 256 kernels of size 5x5, stride=1, padding=2\n","- input : 27x27x96\n","- output : 27x27x256\n","\n","6. MaxPool2\n",": 3x3 kernels, stride=2\n","- input : 27x27x96\n","- output : 13x13x256\n","\n","7. Norm2\n","- input : 13x13x256\n","- output : 13x13x256\n","\n","8. Conv3\n",": 384 kerenels of size 3x3, stride=1, padding=1\n","- input : 13x13x256\n","- output : 13x13x384\n","\n","9. Conv4\n",": 384 kernels of size 3x3, stride=1, padding=1\n","- input : 13x13x384\n","- output : 13x13x384\n","\n","10. Conv5\n",": 256 kernels fo size 3x3, stride=1, padding=1\n","- input : 13x13x384\n","- output : 13x13x256\n","\n","11. MaxPool3\n",": 3x3 kernels, stride=2\n","- input : 13x13x256\n","- output : 6x6x256\n","\n","12. FC1\n",": fc layer with 4096 neurons\n","- input : 6x6x256\n","- output : 4096\n","\n","13. FC2\n",": fc layer with 4096 neurons\n","- input : 4096\n","- output : 4096\n","\n","14. Output Layer\n",": fc layer with 1000-way softmax\n","- input : 4096\n","- output : 1000"],"metadata":{"id":"u6I-KtDOqaxD"}},{"cell_type":"markdown","source":["AlexNet의 구조에 적용된 특징"],"metadata":{"id":"cnzJX3y9ssMu"}},{"cell_type":"markdown","source":["1. ReLU Nonlinearity\n","\n"],"metadata":{"id":"q6FXmtySsj5a"}},{"cell_type":"markdown","source":["2. Training on Multiple GPUs\n","\n",": 2 GPU training (gpu parallelization)\n","\n"],"metadata":{"id":"5DXVQqHysv-u"}},{"cell_type":"markdown","source":["데이터를 두 개의 gpu로 학습 후 하나의 layer에만 gpu를 통합."],"metadata":{"id":"RQA5JeRns6-2"}},{"cell_type":"markdown","source":["3. Local Response Normalization(LRN)\n","\n",": LRN은 generalization을 목적으로 한다. 본 논문은 ReLU를 사용하여 non-saturating nonlinearity의 특징으로 하여금 vanishing gradient를 제거.\n","\n","또한 ReLU는 normalization이 필요하지 않음.\n","\n","추가적으로 양수값을 받으면 그 값 그대로 neuron에 전달되기에 너무 큰 값이 전달되어 주변의 낮은 값이 neuron에 전달되는 것을 막을 수 있음.\n","\n","\n","AlexNet 이후 현대 CNN에는 LRN대신 batch normalization을 사용함"],"metadata":{"id":"t3FFLcS2s_9o"}},{"cell_type":"markdown","source":["4. Overlapping Pooling"],"metadata":{"id":"88TJzwQZtwsk"}},{"cell_type":"markdown","source":["#Reducing Overfitting"],"metadata":{"id":"QGIIRTMmt0yH"}},{"cell_type":"markdown","source":["1. Data Augmentation\n","\n",": 적은 노력으로 다양한 데이터를 형성하여  overfitting 방지.\n","\n","- generating image translation and horizontal reflections\n",": 256x256을 224x224로 crop(중앙, 좌우 상하) --> horizontal reflection\n","\n","- altering the intensities of RGB channels in training images\n",": rgb pixel 값 변화"],"metadata":{"id":"WoJhW_Trt4Bq"}},{"cell_type":"markdown","source":["2. Dropout\n",": 매 입력마다 0.5의 확률로 순전파와 역전파를 진행\n","\n","- AlexNet은 두 개의 FC 에서만 dropout 진행"],"metadata":{"id":"_WVD-wDKud6Y"}},{"cell_type":"markdown","source":["#Details of learning\n","HyperParameter _ SGD(stochastic gradient descent)\n","- Momentum=0.9\n","- batch_size =128,\n","- weight_decay=0.005\n","\n","vi+1 := 0.9*vi - 0.0005*e*wi - e*<əL/əW>\n","\n","wi+1 := wi+vi+1\n","\n","\n","\n","weight 초기화는 (0,0.01)\n","bias는 Conv2,4,5 Fc layer1, 나머지 layer는 0"],"metadata":{"id":"RVIULonbusuT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"R31Uks_H8fd9"},"outputs":[],"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","from torch.utils from data\n","\n","import torchvision.datasets import datasets\n","import torchvision.transforms as transforms\n","\n","from tensorboardX import SummaryWriter"]},{"cell_type":"code","source":["#Pytorch devide 정의 / gpu사용\n","device = torch.device('cuda' if torch.cuda.is_availabel() else 'cpu')"],"metadata":{"id":"cUn34G40vzq-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#model parameters 정의\n","NUM_EPOCHS = 90\n","BATCH_SIZE = 128\n","MOMENTUM = 0.9\n","LR_DECAY = 0.0005\n","LR_INIT = 0.01\n","IMAGE_DIM = 227 #pixels\n","NUM_CLASSES = 1000\n","DEVICE_IDS = [0,1,2,3]"],"metadata":{"id":"00_5V4cAv55K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#data directory 지정\n","INPUT_ROOT_DIR = 'alexnet_data_in'\n","TRAIN_IMG_DIR = 'alexnet_data_in/imagenet'\n","OUTPUT_DIR = 'alexnet_data_out'\n","LOG_DIR = OUTPUT_DIR + '/tblogs'    #tensorboard logs\n","CHECKPOINT_DIR = OUTPUT_DIR + '/models'   #model checkpoints\n","\n","#checkpoint 경로 directory 만들기\n","os.makedirs(CHECKPOINT_DIR, exist_ok = True)"],"metadata":{"id":"rcjWW6XYwGRb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AlexNet(nn.Module) :\n","  def __init__(self, num_classes=1000) :\n","    super().__init__()\n","    #input size : (bx3x227x227)\n","    #본 논문에서는 image 크기가 224pixel이라고 하지만, conv1d 이후 차원은 55x55\n","    #따라서 227x227로 변경\n","    self.net = nn.Sequential(\n","        nn.Conv2d(in_channel=3, out_channel=96, kernel_size=11, stride=4),\n","        nn.ReLU(),\n","        nn.LocalResponseNorm(size=5, alpha=0.001, beta = 0.75, k=2),#LRN    값은 논문에서 사용한 값을 사용\n","        nn.MaxPool2d(kernel=3, stride=2),     #maxpooling\n","\n","        nn.Conv2d(96,256,5,padding=2),\n","        nn.ReLU(),\n","        nn.LocalResponseNorm(size=5, alpha=0.001, beta = 0.75, k=2),\n","        nn.MaxPool2d(kernel_size=3, stride=2),\n","        nn.ReLU(),\n","\n","        nn.Conv2d(256,384,3, padding=1),\n","        nn.ReLU(),\n","        nn.Conv2d(384,384,3, padding=1),\n","        nn.ReLU(),\n","        nn.Conv2d(384,256,3, padding=1),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=3, stride=2)\n","    )\n","\n","    #Fc Layer\n","    self.classifier = nn.Sequential(\n","        nn.Dropout(p=0.5, inplace=True),\n","        nn.Linear(in_features = (256*6*6), out_features = 4096),\n","        nn.ReLU(),\n","\n","        nn.Dropout(p=0.5, inplace=True),\n","        nn.Linear(in_features = 4096, out_features = 4096),\n","        nn.LeRU(),\n","\n","        nn.Linear(in_features = 4096, out_features = num_classes)\n","    )\n","    self.init_bias()\n","\n","\n","  def init_bias(self) :\n","    for layer in self.net :\n","      if isinstance(layer, nn.Conv2d) :\n","        #weight과 bias 초기화\n","        nn.init.nornam_(layer.weight, mean=0, std=0.1)\n","        nn.init.constant_(layer.bias, 0)\n","    #논문에서는 2,4,5 conv2d layer의 bias는 1로 초기화\n","    nn.init.constant_(self.net[4].bias, 1)\n","    nn.init.constant_(self.net[10].bias, 1)\n","    nn.init.constant_(self.net[12].bias, 1)\n","\n","\n","  def forward(self, x):\n","    x= self.net()\n","    x= x.view(-1,256*6*6)\n","  return self.classifier(x)\n",""],"metadata":{"id":"m9uZlgGHwhzj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["데이터 전처리, 손실함수, optimizer, 학습"],"metadata":{"id":"gmbuG_c80hph"}},{"cell_type":"code","source":["if __name__ == '__main__':\n","    # seed value 출력하기\n","    seed = torch.initial_seed()\n","    print('Used seed : {}'.format(seed))\n","\n","    tbwriter = SummaryWriter(log_dir=LOG_DIR)\n","    print('TensorboardX summary writer created')\n","\n","    # model 생성하기\n","    alexnet = AlexNet(num_classes=NUM_CLASSES).to(device)\n","    # 다수의 GPU에서 train\n","    alexnet = torch.nn.parallel.DataParallel(alexnet, device_ids=DEVICE_IDS)\n","    print(alexnet)\n","    print('AlexNet created')\n","\n","    # dataset과 data loader 생성하기\n","    dataset = datasets.ImageFolder(TRAIN_IMG_DIR, transforms.Compose([\n","        # transforms.RandomResizedCrop(IMAGE_DIM, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n","        transforms.CenterCrop(IMAGE_DIM),\n","        # transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ]))\n","    print('Dataset created')\n","    dataloader = data.DataLoader(\n","        dataset,\n","        shuffle=True,\n","        pin_memory=True,\n","        num_workers=8,\n","        drop_last=True,\n","        batch_size=BATCH_SIZE)\n","    print('Dataloader created')\n","\n","    # optimizer 생성하기\n","    optimizer = optim.SGD(\n","        params=alexnet.parameters(),      #alexnet의 parameter를 params에 저장\n","        lr=LR_INIT,\n","        momentum=MOMENTUM,      #momentum사용\n","        weight_decay=LR_DECAY)\n","    print('Optimizer created')\n","\n","    # lr_scheduler로 LR 감소시키기 : 30epochs 마다 1/10\n","    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n","    print('LR Scheduler created')\n","\n","    # train 시작\n","    print('Starting training...')\n","    total_steps = 1\n","    for epoch in range(NUM_EPOCHS):\n","        lr_scheduler.step()\n","        for imgs, classes in dataloader:\n","            imgs, classes = imgs.to(device), classes.to(device)\n","\n","            # loss 계산\n","            output = alexnet(imgs)\n","            loss = F.cross_entropy(output, classes)\n","\n","            # parameter 갱신\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            # log the information and add to tensorboard\n","            # 정보를 기록하고 tensorboard에 추가하기\n","            if total_steps % 10 == 0:\n","                with torch.no_grad():\n","                    _, preds = torch.max(output, 1)\n","                    accuracy = torch.sum(preds == classes)\n","\n","                    print('Epoch: {} \\tStep: {} \\tLoss: {:.4f} \\tAcc: {}'\n","                        .format(epoch + 1, total_steps, loss.item(), accuracy.item()))\n","                    tbwriter.add_scalar('loss', loss.item(), total_steps)\n","                    tbwriter.add_scalar('accuracy', accuracy.item(), total_steps)\n","\n","            # gradient values와 parameter average values 추력하기\n","            if total_steps % 100 == 0:\n","                with torch.no_grad():\n","                    # parameters의 grad 출력하고 저장하기\n","                    # parameters values 출력하고 저장하기\n","                    print('*' * 10)\n","                    for name, parameter in alexnet.named_parameters():\n","                        if parameter.grad is not None:\n","                            avg_grad = torch.mean(parameter.grad)\n","                            print('\\t{} - grad_avg: {}'.format(name, avg_grad))\n","                            tbwriter.add_scalar('grad_avg/{}'.format(name), avg_grad.item(), total_steps)\n","                            tbwriter.add_histogram('grad/{}'.format(name),\n","                                    parameter.grad.cpu().numpy(), total_steps)\n","                        if parameter.data is not None:\n","                            avg_weight = torch.mean(parameter.data)\n","                            print('\\t{} - param_avg: {}'.format(name, avg_weight))\n","                            tbwriter.add_histogram('weight/{}'.format(name),\n","                                    parameter.data.cpu().numpy(), total_steps)\n","                            tbwriter.add_scalar('weight_avg/{}'.format(name), avg_weight.item(), total_steps)\n","\n","            total_steps += 1\n","\n","        # checkpoints 저장하기\n","        checkpoint_path = os.path.join(CHECKPOINT_DIR, 'alexnet_states_e{}.pkl'.format(epoch + 1))\n","        state = {\n","            'epoch': epoch,\n","            'total_steps': total_steps,\n","            'optimizer': optimizer.state_dict(),\n","            'model': alexnet.state_dict(),\n","            'seed': seed,\n","        }\n","        torch.save(state, checkpoint_path)"],"metadata":{"id":"lJKtaZ0m0lhi"},"execution_count":null,"outputs":[]}]}